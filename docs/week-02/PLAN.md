# üöÄ Week 2: Data Integration - –î–µ—Ç–∞–ª—å–Ω—ã–π –ü–ª–∞–Ω

**–¶–µ–ª—å:** –ü–æ–¥–∫–ª—é—á–∏—Ç—å —Ä–µ–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —Å Hyperliquid –∏ —Å–æ–∑–¥–∞—Ç—å data pipeline.

**–°—Ç–∞—Ç—É—Å:** üîÑ In Progress  
**–í—Ä–µ–º—è:** 5-7 –¥–Ω–µ–π  
**–°–ª–æ–∂–Ω–æ—Å—Ç—å:** Medium

---

## üìä –û–±–∑–æ—Ä

–ü–æ—Å–ª–µ —É—Å–ø–µ—à–Ω–æ–≥–æ Week 1 (Strategy Framework + EV + Risk) —É –Ω–∞—Å –µ—Å—Ç—å:
- ‚úÖ –†–∞–±–æ—Ç–∞—é—â–∏–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ (Tortoise)
- ‚úÖ EV –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä —Å –ø–æ–ª–Ω—ã–º–∏ –∏–∑–¥–µ—Ä–∂–∫–∞–º–∏
- ‚úÖ Risk Manager —Å sizing
- ‚úÖ Integration demo –Ω–∞ fake –¥–∞–Ω–Ω—ã—Ö

**–ü—Ä–æ–±–ª–µ–º–∞:** –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ ‚Üí –Ω—É–∂–Ω—ã —Ä–µ–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ.

**–†–µ—à–µ–Ω–∏–µ:** –ü–æ–¥–∫–ª—é—á–∏—Ç—å Hyperliquid API ‚Üí —Å–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ ‚Üí —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ Parquet ‚Üí –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ —Å—Ç—Ä–∞—Ç–µ–≥–∏—è—Ö.

---

## üéØ –¶–µ–ª–∏ Week 2

### –ì–ª–∞–≤–Ω–∞—è —Ü–µ–ª—å
–ó–∞–ø—É—Å—Ç–∏—Ç—å Tortoise —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –Ω–∞ **—Ä–µ–∞–ª—å–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö** BTC-PERP –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 2 –≥–æ–¥–∞.

### –ö–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ deliverables
1. ‚úÖ TypeScript Hyperliquid adapter (REST API)
2. ‚úÖ Python data fetcher (—Å–∫–∞—á–∏–≤–∞–Ω–∏–µ candles)
3. ‚úÖ Parquet storage (–±—ã—Å—Ç—Ä–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ)
4. ‚úÖ Historical data –¥–ª—è BTC/ETH (1D, 4H, 1H)
5. ‚úÖ Integration test –Ω–∞ real data
6. ‚úÖ –°—Ä–∞–≤–Ω–µ–Ω–∏–µ: fake data vs real data results

---

## üìã –ó–∞–¥–∞—á–∏ (–¥–µ—Ç–∞–ª—å–Ω–æ)

### Phase 1: Hyperliquid REST API (–î–µ–Ω—å 1-2)

#### –ó–∞–¥–∞—á–∞ 1.1: TypeScript Adapter
**–§–∞–π–ª:** `core/exchanges/hyperliquid/HyperliquidExchange.ts`

**–ß—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å:**
```typescript
class HyperliquidExchange implements IExchange {
  // –ü—É–±–ª–∏—á–Ω—ã–µ endpoints (–Ω–µ —Ç—Ä–µ–±—É—é—Ç auth)
  async getCandles(market: string, interval: string, startTime: number, endTime: number)
  async getFunding(market: string)
  async getMarkets(): Promise<Market[]>
  
  // Meta info
  async getFeeSchedule(): Promise<FeeSchedule>
  
  // –£–∂–µ –µ—Å—Ç—å –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ
  orderbook(pair: string): Promise<OrderBookL2>
  trades(pair: string, since?: number): AsyncIterable<Trade>
}
```

**API endpoints:**
- `POST https://api.hyperliquid.xyz/info` - —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π endpoint
- Request body: `{"type": "candles", "req": {...}}`
- Response: –º–∞—Å—Å–∏–≤ OHLCV

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**
- Intervals: `1m`, `5m`, `15m`, `1h`, `4h`, `1d`
- Markets: `BTC`, `ETH`, `SOL`, etc (–±–µ–∑ `-PERP` —Å—É—Ñ—Ñ–∏–∫—Å–∞ –≤ API)
- Time: Unix timestamp –≤ –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥–∞—Ö

**Best practices:**
- Rate limiting: 1200 requests/minute
- Retry logic —Å exponential backoff
- Error handling –¥–ª—è network issues
- Type safety (Zod schemas –¥–ª—è validation)

**–ü—Ä–∏–º–µ—Ä –∑–∞–ø—Ä–æ—Å–∞:**
```typescript
const response = await fetch('https://api.hyperliquid.xyz/info', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    type: 'candles',
    req: {
      coin: 'BTC',
      interval: '1d',
      startTime: 1640000000000,
      endTime: 1700000000000
    }
  })
})
```

**Testing:**
```bash
# Test endpoint
curl -X POST https://api.hyperliquid.xyz/info \
  -H "Content-Type: application/json" \
  -d '{"type": "candles", "req": {"coin": "BTC", "interval": "1d", "startTime": 1640000000000}}'
```

---

#### –ó–∞–¥–∞—á–∞ 1.2: Python Wrapper
**–§–∞–π–ª:** `core/data/hyperliquid_client.py`

**–ó–∞—á–µ–º:** Python –ø—Ä–æ—â–µ –¥–ª—è data processing, –∞ TypeScript –¥–ª—è live trading.

**–ß—Ç–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å:**
```python
class HyperliquidClient:
    def __init__(self, base_url: str = "https://api.hyperliquid.xyz"):
        self.base_url = base_url
        self.session = requests.Session()
    
    def get_candles(
        self,
        coin: str,
        interval: str,
        start_time: int,
        end_time: int
    ) -> pd.DataFrame:
        """
        –ü–æ–ª—É—á–∏—Ç—å —Å–≤–µ—á–∏ —Å Hyperliquid.
        
        Returns:
            DataFrame —Å –∫–æ–ª–æ–Ω–∫–∞–º–∏: timestamp, open, high, low, close, volume
        """
        pass
    
    def get_funding_history(self, coin: str) -> pd.DataFrame:
        """–ü–æ–ª—É—á–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é funding rates."""
        pass
```

**Best practices:**
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `requests.Session()` –¥–ª—è connection pooling
- –î–æ–±–∞–≤–∏—Ç—å retry decorator (@retry)
- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
- –ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–≤–µ—Ç–æ–≤ (optional)

---

### Phase 2: Data Fetcher & Storage (–î–µ–Ω—å 2-3)

#### –ó–∞–¥–∞—á–∞ 2.1: Data Fetcher
**–§–∞–π–ª:** `core/data/fetcher.py`

**–ß—Ç–æ –¥–µ–ª–∞–µ—Ç:**
1. –ü—Ä–∏–Ω–∏–º–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã: market, interval, date range
2. –†–∞–∑–±–∏–≤–∞–µ—Ç –Ω–∞ chunks (API –ª–∏–º–∏—Ç ~1000 —Å–≤–µ—á–µ–π –∑–∞ –∑–∞–ø—Ä–æ—Å)
3. –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å–∫–∞—á–∏–≤–∞–µ—Ç chunks (concurrent requests)
4. –û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤ –æ–¥–∏–Ω DataFrame
5. –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ (–Ω–µ—Ç gaps, –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ OHLC)

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞:**
```python
class DataFetcher:
    def __init__(self, client: HyperliquidClient):
        self.client = client
    
    def fetch_historical(
        self,
        market: str,
        interval: str,
        start_date: str,  # "2022-01-01"
        end_date: str,    # "2024-10-01"
        validate: bool = True
    ) -> pd.DataFrame:
        """
        –°–∫–∞—á–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ —Å –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏.
        """
        # 1. Parse dates ‚Üí timestamps
        # 2. Calculate chunks (1000 candles per request)
        # 3. Fetch chunks (parallel with rate limiting)
        # 4. Merge & sort
        # 5. Validate (no gaps, OHLC valid)
        # 6. Return DataFrame
        pass
    
    def _validate_candles(self, df: pd.DataFrame) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö."""
        # Check: high >= open/close/low
        # Check: low <= open/close/high
        # Check: no gaps in timestamps
        # Check: volume >= 0
        pass
```

**–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞:**
```python
import asyncio
import aiohttp

async def fetch_chunk_async(coin, interval, start, end):
    async with aiohttp.ClientSession() as session:
        # async request
        pass

# Fetch multiple chunks in parallel
chunks = await asyncio.gather(*[
    fetch_chunk_async(coin, interval, chunk_start, chunk_end)
    for chunk_start, chunk_end in chunk_ranges
])
```

---

#### –ó–∞–¥–∞—á–∞ 2.2: Parquet Storage
**–§–∞–π–ª:** `core/data/storage.py`

**–ó–∞—á–µ–º Parquet:**
- Columnar format ‚Üí –±—ã—Å—Ç—Ä–µ–µ —á–µ–º CSV (10-100x)
- Compression ‚Üí –º–µ–Ω—å—à–µ –º–µ—Å—Ç–∞ (–¥–æ 10x)
- Metadata ‚Üí —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è
- Pandas native support

**–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ö—Ä–∞–Ω–∏–ª–∏—â–∞:**
```
data/
  candles/
    BTC-PERP/
      1d.parquet       # –î–Ω–µ–≤–Ω—ã–µ —Å–≤–µ—á–∏
      4h.parquet       # 4-—á–∞—Å–æ–≤—ã–µ
      1h.parquet       # –ß–∞—Å–æ–≤—ã–µ
    ETH-PERP/
      1d.parquet
      ...
  funding/
    BTC-PERP.parquet   # –ò—Å—Ç–æ—Ä–∏—è funding rates
  metadata/
    last_update.json   # –ö–æ–≥–¥–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑ –æ–±–Ω–æ–≤–ª—è–ª–∏
```

**–ö–æ–¥:**
```python
class ParquetStorage:
    def __init__(self, data_dir: Path = Path("./data")):
        self.data_dir = data_dir
    
    def save_candles(
        self,
        market: str,
        interval: str,
        df: pd.DataFrame
    ):
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–≤–µ—á–∏ –≤ Parquet."""
        path = self.data_dir / "candles" / market / f"{interval}.parquet"
        path.parent.mkdir(parents=True, exist_ok=True)
        df.to_parquet(path, compression='snappy', index=False)
    
    def load_candles(
        self,
        market: str,
        interval: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None
    ) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∑–∏—Ç—å —Å–≤–µ—á–∏ –∏–∑ Parquet —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ –¥–∞—Ç–µ."""
        path = self.data_dir / "candles" / market / f"{interval}.parquet"
        df = pd.read_parquet(path)
        
        # Filter by date range
        if start_date:
            df = df[df['timestamp'] >= pd.to_datetime(start_date).timestamp() * 1000]
        if end_date:
            df = df[df['timestamp'] <= pd.to_datetime(end_date).timestamp() * 1000]
        
        return df
    
    def update_candles(self, market: str, interval: str, new_df: pd.DataFrame):
        """Incremental update: –¥–æ–±–∞–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ —Å–≤–µ—á–∏."""
        try:
            existing = self.load_candles(market, interval)
            # Merge: keep existing + add new
            combined = pd.concat([existing, new_df]).drop_duplicates(subset='timestamp')
            combined = combined.sort_values('timestamp').reset_index(drop=True)
            self.save_candles(market, interval, combined)
        except FileNotFoundError:
            # First time - just save
            self.save_candles(market, interval, new_df)
```

---

### Phase 3: Initial Data Download (–î–µ–Ω—å 3-4)

#### –ó–∞–¥–∞—á–∞ 3.1: –°–∫—Ä–∏–ø—Ç –∑–∞–≥—Ä—É–∑–∫–∏
**–§–∞–π–ª:** `scripts/download_initial_data.py`

**–ß—Ç–æ —Å–∫–∞—á–∏–≤–∞–µ–º:**

| Market | Intervals | Period | –ü—Ä–∏–º–µ—Ä–Ω—ã–π —Ä–∞–∑–º–µ—Ä |
|--------|-----------|--------|------------------|
| BTC-PERP | 1d, 4h, 1h | 2 –≥–æ–¥–∞ | ~50 MB |
| ETH-PERP | 1d, 4h, 1h | 2 –≥–æ–¥–∞ | ~50 MB |

**–°–∫—Ä–∏–ø—Ç:**
```python
#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–µ—Ä–≤–∏—á–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö.

Usage:
    python scripts/download_initial_data.py --market BTC-PERP --days 730
    python scripts/download_initial_data.py --all  # –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å—ë
"""

import argparse
from core.data.hyperliquid_client import HyperliquidClient
from core.data.fetcher import DataFetcher
from core.data.storage import ParquetStorage

def download_market_data(market: str, days: int = 730):
    """–°–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ä—ã–Ω–∫–∞."""
    print(f"üì• Downloading {market} data...")
    
    client = HyperliquidClient()
    fetcher = DataFetcher(client)
    storage = ParquetStorage()
    
    # Calculate date range
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)
    
    # Download each interval
    for interval in ['1d', '4h', '1h']:
        print(f"  ‚è≥ Fetching {interval} candles...")
        df = fetcher.fetch_historical(
            market=market,
            interval=interval,
            start_date=start_date.strftime('%Y-%m-%d'),
            end_date=end_date.strftime('%Y-%m-%d')
        )
        
        print(f"  ‚úÖ {len(df)} candles fetched")
        storage.save_candles(market, interval, df)
        print(f"  üíæ Saved to data/candles/{market}/{interval}.parquet")

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--market', help='Market to download (e.g., BTC-PERP)')
    parser.add_argument('--days', type=int, default=730, help='Days of history')
    parser.add_argument('--all', action='store_true', help='Download all markets')
    args = parser.parse_args()
    
    if args.all:
        markets = ['BTC-PERP', 'ETH-PERP']
        for market in markets:
            download_market_data(market, args.days)
    elif args.market:
        download_market_data(args.market, args.days)
    else:
        print("‚ùå Specify --market or --all")
        sys.exit(1)
    
    print("\nüéâ Download complete!")

if __name__ == '__main__':
    main()
```

**–ó–∞–ø—É—Å–∫:**
```bash
# –ó–∞–≥—Ä—É–∑–∏—Ç—å BTC –∑–∞ 2 –≥–æ–¥–∞
python scripts/download_initial_data.py --market BTC-PERP --days 730

# –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤—Å—ë
python scripts/download_initial_data.py --all
```

---

### Phase 4: Integration —Å –°—Ç—Ä–∞—Ç–µ–≥–∏—è–º–∏ (–î–µ–Ω—å 4-5)

#### –ó–∞–¥–∞—á–∞ 4.1: –ú–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å Tortoise
**–§–∞–π–ª:** `core/strategy/tortoise.py`

**–ß—Ç–æ –∏–∑–º–µ–Ω–∏—Ç—å:**
- –£–±—Ä–∞—Ç—å fake data generation
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å real data –∏–∑ Parquet storage

**–î–æ:**
```python
# –í demo —Ç–µ—Å—Ç–µ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª–∏:
history = generate_fake_history(days=100)
```

**–ü–æ—Å–ª–µ:**
```python
# –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ storage:
from core.data.storage import ParquetStorage

storage = ParquetStorage()
history = storage.load_candles(
    market='BTC-PERP',
    interval='1d',
    start_date='2022-01-01',
    end_date='2024-10-01'
)
```

---

#### –ó–∞–¥–∞—á–∞ 4.2: –ù–æ–≤—ã–π Integration Test
**–§–∞–π–ª:** `tests/test_real_data_integration.py`

**–ß—Ç–æ —Ç–µ—Å—Ç–∏—Ä—É–µ–º:**
```python
def test_tortoise_on_real_data():
    """
    –¢–µ—Å—Ç Tortoise —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö BTC.
    """
    # 1. Load real data
    storage = ParquetStorage()
    history = storage.load_candles('BTC-PERP', '1d', '2023-01-01', '2024-01-01')
    
    # 2. Initialize strategy
    strategy = TortoiseStrategy({...})
    
    # 3. Run through all bars
    signals = []
    for i in range(20, len(history)):  # Start after warmup period
        bar = history.iloc[i]
        ctx = BarContext(...)
        sigs = strategy.on_bar(ctx, history[:i])
        signals.extend(sigs)
    
    # 4. Analyze results
    print(f"Total signals: {len(signals)}")
    print(f"Long signals: {sum(1 for s in signals if s.side == 'long')}")
    print(f"Short signals: {sum(1 for s in signals if s.side == 'short')}")
    
    # 5. Assert
    assert len(signals) > 0, "No signals generated!"
```

---

### Phase 5: Data Quality & Monitoring (–î–µ–Ω—å 5)

#### –ó–∞–¥–∞—á–∞ 5.1: Data Validation
**–§–∞–π–ª:** `core/data/validator.py`

**–ü—Ä–æ–≤–µ—Ä–∫–∏:**
```python
class DataValidator:
    @staticmethod
    def validate_ohlc(df: pd.DataFrame) -> List[str]:
        """Validate OHLC relationships."""
        errors = []
        
        # High >= all others
        if (df['high'] < df['open']).any():
            errors.append("High < Open detected")
        if (df['high'] < df['close']).any():
            errors.append("High < Close detected")
        if (df['high'] < df['low']).any():
            errors.append("High < Low detected")
        
        # Low <= all others
        if (df['low'] > df['open']).any():
            errors.append("Low > Open detected")
        if (df['low'] > df['close']).any():
            errors.append("Low > Close detected")
        
        # Volume >= 0
        if (df['volume'] < 0).any():
            errors.append("Negative volume detected")
        
        return errors
    
    @staticmethod
    def check_gaps(df: pd.DataFrame, interval: str) -> List[int]:
        """Find timestamp gaps."""
        interval_ms = {
            '1m': 60_000,
            '5m': 300_000,
            '15m': 900_000,
            '1h': 3_600_000,
            '4h': 14_400_000,
            '1d': 86_400_000
        }[interval]
        
        gaps = []
        for i in range(1, len(df)):
            expected = df.iloc[i-1]['timestamp'] + interval_ms
            actual = df.iloc[i]['timestamp']
            if actual != expected:
                gaps.append(i)
        
        return gaps
```

---

#### –ó–∞–¥–∞—á–∞ 5.2: Metadata Tracking
**–§–∞–π–ª:** `data/metadata/last_update.json`

**–§–æ—Ä–º–∞—Ç:**
```json
{
  "BTC-PERP": {
    "1d": {
      "last_timestamp": 1697932800000,
      "last_update": "2024-10-21T10:30:00Z",
      "total_candles": 730,
      "first_timestamp": 1634083200000
    },
    "4h": {...},
    "1h": {...}
  },
  "ETH-PERP": {...}
}
```

**–ó–∞—á–µ–º:**
- –ó–Ω–∞–µ–º –∫–æ–≥–¥–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑ –æ–±–Ω–æ–≤–ª—è–ª–∏
- Incremental updates (—Å–∫–∞—á–∏–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ)
- –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö

---

## üß™ Testing Strategy

### Unit Tests
```python
# test_hyperliquid_client.py
def test_get_candles():
    client = HyperliquidClient()
    df = client.get_candles('BTC', '1d', start, end)
    assert len(df) > 0
    assert 'close' in df.columns

# test_storage.py
def test_save_load_parquet():
    storage = ParquetStorage()
    df_original = ...
    storage.save_candles('BTC-PERP', '1d', df_original)
    df_loaded = storage.load_candles('BTC-PERP', '1d')
    assert df_original.equals(df_loaded)
```

### Integration Tests
```python
# test_end_to_end_data_pipeline.py
def test_full_pipeline():
    # 1. Fetch from API
    # 2. Save to Parquet
    # 3. Load from Parquet
    # 4. Use in strategy
    # 5. Generate signals
    pass
```

---

## üìà Success Metrics

–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ Week 2 —Å—á–∏—Ç–∞–µ—Ç—Å—è —É—Å–ø–µ—à–Ω—ã–º –µ—Å–ª–∏:

‚úÖ **Data Pipeline Works**
- [ ] –ú–æ–∂–µ–º —Å–∫–∞—á–∞—Ç—å 2 –≥–æ–¥–∞ BTC-PERP –¥–∞–Ω–Ω—ã—Ö –∑–∞ < 5 –º–∏–Ω—É—Ç
- [ ] –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è –≤ Parquet (< 100 MB –¥–ª—è BTC+ETH)
- [ ] –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ Parquet < 1 —Å–µ–∫—É–Ω–¥—ã

‚úÖ **Data Quality**
- [ ] 0 OHLC validation errors
- [ ] < 5 timestamp gaps (–¥–æ–ø—É—Å—Ç–∏–º—ã –≤ –≤—ã—Ö–æ–¥–Ω—ã–µ/–ø—Ä–∞–∑–¥–Ω–∏–∫–∏)
- [ ] Volume > 0 –¥–ª—è –≤—Å–µ—Ö —Å–≤–µ—á–µ–π

‚úÖ **Strategy Integration**
- [ ] Tortoise –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ real data
- [ ] Signals count: 10-50 –∑–∞ 2 –≥–æ–¥–∞ (—Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ –¥–ª—è —Ç—Ä–µ–Ω–¥–æ–≤–æ–π —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏)
- [ ] EV_net –æ—Å—Ç–∞–µ—Ç—Å—è > 0 –Ω–∞ real data

‚úÖ **Documentation**
- [ ] Hyperliquid API guide –Ω–∞–ø–∏—Å–∞–Ω
- [ ] Data pipeline –¥–æ–∫—É–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω
- [ ] –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ä–∞–±–æ—Ç–∞—é—Ç

---

## üö® –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

### Problem 1: Rate Limiting
**Symptom:** 429 Too Many Requests  
**Solution:**
- –î–æ–±–∞–≤–∏—Ç—å delay –º–µ–∂–¥—É requests (0.05s)
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å exponential backoff
- Parallel requests —Å semaphore (max 10 concurrent)

### Problem 2: Data Gaps
**Symptom:** Missing candles –≤ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –ø–µ—Ä–∏–æ–¥—ã  
**Solution:**
- –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å gaps –Ω–æ –Ω–µ –ø–∞–¥–∞—Ç—å
- –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏—è (forward fill)
- –ü–æ–º–µ—Ç–∫–∞ –≤ metadata

### Problem 3: Inconsistent Data
**Symptom:** High < Low, negative volume  
**Solution:**
- –°—Ç—Ä–æ–≥–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –ø–æ—Å–ª–µ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è
- –û—Ç–±—Ä–∞—Å—ã–≤–∞—Ç—å invalid candles
- –õ–æ–≥–∏—Ä–æ–≤–∞—Ç—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞

### Problem 4: API Changes
**Symptom:** Response format –∏–∑–º–µ–Ω–∏–ª—Å—è  
**Solution:**
- Zod schemas –¥–ª—è runtime validation
- Version –≤ API client
- Unit tests –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö responses (fixtures)

---

## üìä Deliverables Checklist

### Code
- [ ] `core/exchanges/hyperliquid/HyperliquidExchange.ts`
- [ ] `core/data/hyperliquid_client.py`
- [ ] `core/data/fetcher.py`
- [ ] `core/data/storage.py`
- [ ] `core/data/validator.py`
- [ ] `scripts/download_initial_data.py`
- [ ] `scripts/update_data.py` (incremental updates)

### Data
- [ ] `data/candles/BTC-PERP/1d.parquet`
- [ ] `data/candles/BTC-PERP/4h.parquet`
- [ ] `data/candles/BTC-PERP/1h.parquet`
- [ ] `data/candles/ETH-PERP/...` (same structure)
- [ ] `data/metadata/last_update.json`

### Tests
- [ ] `tests/test_hyperliquid_client.py`
- [ ] `tests/test_data_fetcher.py`
- [ ] `tests/test_storage.py`
- [ ] `tests/test_real_data_integration.py`

### Documentation
- [ ] `docs/week-02/HYPERLIQUID_INTEGRATION.md`
- [ ] `docs/week-02/DATA_PIPELINE.md`
- [ ] Update `docs/QUICKSTART.md` with real data instructions

---

## üéØ Next Steps (Week 3 Preview)

–ü–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è Week 2 —É –Ω–∞—Å –±—É–¥–µ—Ç:
- ‚úÖ Real historical data
- ‚úÖ Tortoise –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–∏–≥–Ω–∞–ª—ã –Ω–∞ real data

Week 3:
- üéØ **Simple Backtest Engine** - –ø—Ä–æ–≥–æ–Ω –ø–æ –≤—Å–µ–π –∏—Å—Ç–æ—Ä–∏–∏
- üéØ **Trade Log** - –∑–∞–ø–∏—Å—å –≤—Å–µ—Ö —Å–¥–µ–ª–æ–∫ —Å P&L
- üéØ **Metrics** - Sharpe, MaxDD, cumulative R
- üéØ **Walk-Forward** - –∑–∞—â–∏—Ç–∞ –æ—Ç overfitting
- üéØ **Monte Carlo** - –æ—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤

---

## üìû –í–æ–ø—Ä–æ—Å—ã?

–í–µ—Å—å –∫–æ–¥ –±—É–¥–µ—Ç –ø—Ä–æ–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω –ø–æ—Å—Ç—Ä–æ—á–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º!

**–°–ª–µ–¥—É—é—â–∏–π —Ñ–∞–π–ª:** [HYPERLIQUID_INTEGRATION.md](HYPERLIQUID_INTEGRATION.md) - –¥–µ—Ç–∞–ª–∏ API

---

**–°–æ–∑–¥–∞–Ω–æ:** 21 –æ–∫—Ç—è–±—Ä—è 2025  
**–°—Ç–∞—Ç—É—Å:** Ready to implement  
**ETA:** 5-7 –¥–Ω–µ–π

